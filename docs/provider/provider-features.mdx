---
sidebar_position: 2
slug: /provider-features
title: Features
---

import TOCInline from '@theme/TOCInline';

# Provider Features

This page details the various features available to providers in the Lava network, along with instructions on how to operate them:
<TOCInline toc={toc} />

## Addons and Extensions{#addonsextensions}
Addons and Extensions are services that can be offered *in addition* to the basic spec.
**Addons** are apis exposed in addition to existing apis, while **Extensions** are changes to existing apis responses.
A few examples:
```
"archive" - an extension providing valid responses for older blocks than the current pruning definition in the basic spec
"debug" - an addon that offers debug apis in addition to basic rpc calls
```
### Why Addons and Extensions
consumers can use addons and extensions without configuring anything new in their clients, these are added to the consumer subscription.
requests are routed automatically to providers supporting the services, so a provider supporting a specific Addon will get requests for that addon while providers what do not support it will not be eligible for these requests.
<br>
extensions can also provide a CU boost on the regular api, archive calls for example will have a big multiplier on CU for each api request.
only api requests to the archive endpoint will award these additional CUs, and lava knows which calls are archive or not according to the pruning of the regular spec defined by governance.

### How - Addons and Extensions
Addons and Extensions are configured both in the provider service config, and then staked for on chain.
#### Addon - config
in order to add an addon to the service the yaml must be configured with the addon command
```yaml
endpoints:
    - api-interface: jsonrpc
      chain-id: ETH1
      network-address:
        address: "127.0.0.1:2224"
      node-urls:
        - url: my-eth-node.com/eth-with-debug/ws
          addons:
            - debug
```
#### Extension - config
since extensions must offer consumers the regular spec and the possibility of an extensions, both must be present.<br>
therefore, extensions unlike addons, must be configured in a new url entry:
```yaml
endpoints:
    - api-interface: jsonrpc
      chain-id: ETH1
      network-address:
        address: "127.0.0.1:2224"
      node-urls:
        - url: my-eth-node.com/eth/ws/
        - url: my-eth-node.com/eth-with-archive/ws
          addons:
            - archive
```
although this configuration offers you the chance to load balance different extension calls,<br>
if you run only a single archive node and do not want to automatically load balance archive calls to a pruned node,<br>
you can set both urls to point to the the archive node:
```yaml
endpoints:
    - api-interface: jsonrpc
      chain-id: ETH1
      network-address:
        address: "127.0.0.1:2224"
      node-urls:
        - url: my-eth-node.com/eth-with-archive/ws
        - url: my-eth-node.com/eth-with-archive/ws
          addons:
            - archive
```
additional extensions must be defined with all possible combinations, for example complience + archive will look like this:
```yaml
endpoints:
    - api-interface: jsonrpc
      chain-id: ETH1
      network-address:
        address: "127.0.0.1:2224"
      node-urls:
        - url: my-eth-node.com/eth/ws/
        - url: my-eth-node.com/eth-with-archive/ws
          addons:
            - archive
        - url: my-eth-node.com/eth-with-complience/ws
          addons:
            - complience
        - url: my-eth-node.com/eth-with-complience-and-archive/ws
          addons:
            - complience
            - archive
```

and a combination of an extension and addons will look like this:
```yaml
endpoints:
    - api-interface: jsonrpc
      chain-id: ETH1
      network-address:
        address: "127.0.0.1:2224"
      node-urls:
        - url: my-eth-node.com/eth/ws/archive
          addons:
            - archive
        - url: my-eth-node.com/eth-with-debug/ws
          addons:
            - debug
```

#### Staking
before staking, make sure your process works correctly, if addons or extensions fail to verify the entire service for that spec and api interface will fail, so the test rpcprovider command can be used

staking with an addon or an extensions is very similar to the normal staking command, by adding the list of addons and extensions separated by comma

**Ethereum Mainnet in US with archive and debug**
```bash
lavap tx pairing stake-provider "ETH1" \
    "50000000000ulava" \
    "provider-host.com:443,USC,archive,debug" USC \
    --from "my_account_name" \
    --provider-moniker "your-moniker" \
    --keyring-backend "test" \
    --chain-id "lava-testnet-2" \
    --gas="auto" \
    --gas-adjustment "1.5" \
    --node "https://public-rpc-testnet2.lavanet.xyz:443/rpc/"
```
do note the required addition of **,archive,debug** in each of the endpoints that support it if several exist
setting these in a transaction replaces any existing endpoints, so make sure to give the full list of endpoints
it is also possible to add these to an existing entry with `modify-provider`
```bash
lavap tx pairing modify-provider "ETH1" --endpoints "provider-host.com:443,USC,archive,debug" --geolocation "USC" ...
```

## Freeze and Unfreeze{#freeze}

The **`freeze`** command allows a provider to freeze its service, effective next epoch. This enables providers to pause their services without the impact of a bad QoS rating. While frozen, the provider won't be paired with consumers. To unfreeze, the provider must use the **`unfreeze`** transaction, effective next epoch. This feature can be useful in cases like a provider needing to halt its services during maintenance.

#### Usage

**Freeze:**

```bash
# required flags: --from alice. optional flags: --reason
lavap tx pairing freeze [chain-ids] --from <provider_address>
lavap tx pairing freeze [chain-ids] --from <provider_address> --reason <freeze_reason>
lavap tx pairing freeze ETH1,COS3 --from alice --reason "maintenance"
```

**Unfreeze:**

```bash
# required flags: --from alice
lavap tx pairing unfreeze [chain-ids] --from <provider_address>
lavap tx pairing unfreeze ETH1,COS3 --from alice
```

The **`freeze`** command requires the **`--from`** flag to specify the provider address. Optionally, you can provide a **`--reason`** flag to give a reason for the freeze.

The **`unfreeze`** command also requires the **`--from`** flag to specify the provider address.

## Advanced Auth configuration {#config-auth}
In this example, COS3 tendermint URLs are using client authentication, assuming the node URL is capable of processing this authentication.

### Auth using HTTP headers {#auth-headers}

The following RPCProvider Config Example demonstrated authentication using the "auth-headers" option:

```yaml
endpoints:
  - api-interface: tendermintrpc
    chain-id: COS3
    network-address: 
     address: 127.0.0.1:2221
    node-urls:
      - url: ws://127.0.0.1:26657/websocket
        auth-config:
          auth-headers:
            WANTED_HEADER_NAME_1: xyz
      - url: http://127.0.0.1:26657
        auth-config:
        // highlight-start
          auth-headers:strings.Join(goodChains, "; ")
            Authorization: 'Bearer xxyyzz'
        // highlight-end
```

### Auth using Query Params {#auth-query}

The following RPCProvider Config Example demonstrated authentication using the "auth-query" option:

```yaml
endpoints:
    - api-interface: tendermintrpc
      chain-id: COS3
      network-address: 
        address: 127.0.0.1:2221
      node-urls:
        - url: ws://127.0.0.1:26657/websocket
          // highlight-start
          auth-config:
            auth-query: auth=xxyyzz
          // highlight-end
        - url: http://127.0.0.1:26657
          auth-config:
            auth-query: auth=xyz
```

### gRPC TLS configuration {#grpc-tls}

If you want to add TLS authentication to your gRPC endpoint you have 3 options:

#### 1. Dynamic certificate

```yaml
endpoints:
    - api-interface: grpc
      chain-id: LAV1
      network-address: 
        address: 127.0.0.1:2221
      node-urls:
        - url: 127.0.0.1:9090
          // highlight-start
          auth-config:
            use-tls: true 
          // highlight-end
```

#### 2. Provide a certificate and a key: 

```yaml
endpoints:
    - api-interface: grpc
      chain-id: LAV1
      network-address: 
        address: 127.0.0.1:2221
      node-urls:
        - url: 127.0.0.1:9090
          // highlight-start
          auth-config:
            use-tls: true
            key-pem: /home/user/key.pem
            cert-pem: /home/user/cert.pem
          // highlight-end
```

#### 3. Provide a root certificate:

```yaml
endpoints:
    - api-interface: grpc
      chain-id: LAV1
      network-address: 
        address: 127.0.0.1:2221
      node-urls:
        - url: 127.0.0.1:9090
          // highlight-start
          auth-config:
            use-tls: true
            cacert-pem: /home/user/cert.pem 
          // highlight-end
```

## `ip-forwarding` configuration {#config-ip-forwarding}

If you want to IP load balance / throttle this is also supported by adding "ip-forwarding: true" 
The IP will be added to the following header: `X-Forwarded-For`

```yaml
endpoints:
    - api-interface: jsonrpc
      chain-id: ETH1
      network-address: 
        address: 127.0.0.1:2221
      node-urls: 
        - url: ws://your_node_url/
          // highlight-start
          ip-forwarding: true
          // highlight-end
```

## `node-timeout` configuration {#config-node-timeout}

If your node is too far from the rpcprovider or responds too slowly, and you still want your provider process to start (note this will provide inferior QoS for consumers) without troubleshooting,
you can overwrite the timeouts with custom values using a flag in the node-urls configuration

```yaml
endpoints:
    - api-interface: jsonrpc
      chain-id: ETH1
      network-address: 
        address: 127.0.0.1:2221
      node-urls: 
        - url: ws://your_node_url/
          // highlight-start
          timeout: 1s
          // highlight-end
```

## load balancer configuration {#config-stickyness}
running multiple nodes with a load balancer can have multiple setups:
1. run a provider on each node - provider processes can coexist, if you loadbalance grpc before the process of the provider and run a provider service on each node machine (close proximity)
2. run one provider service and loadbalance the nodes - in this case all the nodes are used by one provider service, this setup is more likely to trigger consistency issues between the provider service and the nodes
<br>
### setting up stickyness support for loadbalanced nodes
if you've set up the second option, meaning one provider service per multiple nodes, it is required to provide stickyness across the nodes by a header <br>
the reason for this being the cryptographic proofs a provider signs, must be consistent and can't have the blocks progress backwards <br>
in order to support stickyness headers lava adds by default a header called `X-Node-Sticky`, this header adds a consumer token consisting of several factors and are unique per consumer usage

### changing the stickyness header
in order to support existing load balancer configs, it is possible to change the header name with a configuration in the config:
```yaml
endpoints:
    - api-interface: jsonrpc
      chain-id: ETH1
      network-address: 
        address: 127.0.0.1:2221
      node-urls: 
        - url: ws://your_node_url/
sticky-header: <your-sticky-header-name>
```
